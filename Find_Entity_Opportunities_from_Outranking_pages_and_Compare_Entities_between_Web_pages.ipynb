{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Find Entity Opportunities from Outranking pages and Compare Entities between Web pages.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBA795waRO5YC74R5wu9+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simodepth/Entities/blob/main/Find_Entity_Opportunities_from_Outranking_pages_and_Compare_Entities_between_Web_pages.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Run a Competitor Analysis by Entities with Google NLP\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Summary**\n",
        "\n",
        "- Compare entities and their salience between two web pages\n",
        "- Display missing entities between two pages\n"
      ],
      "metadata": {
        "id": "grtaB3DVeKRS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Requirements and Assumptions\n",
        "- Python 3 is installed and basic Python syntax understood\n",
        "- Access to a Linux installation (I recommend Ubuntu) or Google Colab\n",
        "- Google Cloud Platform account\n",
        "- [NLP API Enabled](https://cloud.google.com/natural-language/docs)\n",
        "- Credentials created (service account) and JSON file downloaded\n",
        "- NLP JSON key API is uploaded **every time you run this script**"
      ],
      "metadata": {
        "id": "LwxECQqod4_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#! Pip Install Missing Packages\n",
        "- **fake_useragent**: for generating a user agent when making a request\n",
        "- **pandas==1.1.2**: that's simply the newest pandas version"
      ],
      "metadata": {
        "id": "RXcRwl31fLII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fake_useragent\n",
        "\n",
        "!pip install pandas==1.1.2"
      ],
      "metadata": {
        "id": "wlmqZGNLEFYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f7a43d-d605-4c69-8ecb-8bcabf64eb32"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fake_useragent\n",
            "  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n",
            "Building wheels for collected packages: fake-useragent\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=838c67a4d3b4a7dd75b46d8a916b93f2e4f0e8e0f59dac933d2a02dd6c0f9eee\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n",
            "Successfully built fake-useragent\n",
            "Installing collected packages: fake-useragent\n",
            "Successfully installed fake-useragent-0.1.11\n",
            "Collecting pandas==1.1.2\n",
            "  Downloading pandas-1.1.2-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10.5 MB 21.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.2) (2022.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.2) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.1.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.2) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.3.5\n",
            "    Uninstalling pandas-1.3.5:\n",
            "      Successfully uninstalled pandas-1.3.5\n",
            "Successfully installed pandas-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "geNZLeSw3uKF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run Import Modules\n",
        "import os\n",
        "from google.cloud import language_v1\n",
        "from google.cloud.language_v1 import enums\n",
        "\n",
        "from google.cloud import language\n",
        "from google.cloud.language import types\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "from fake_useragent import UserAgent\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Wrap the JSON-LD key API into a call\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/content/nlp-api-348917-9095c7f4e634.json\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RotlfWY0Uwsx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build NLP Function\n",
        "Since we are using the same process to evaluate both pages we can create a function. This helps reduce redundant code. This function named **processhtml()** shown in the code below will:\n",
        "\n",
        "1. Create a new user agent for the request header\n",
        "2. Make the request to the web page and store the HTML content\n",
        "3. Initialize the Google NLP\n",
        "4. Communicate to Google that you are sending them HTML, rather than plain text\n",
        "5. Send the request to Google NLP\n",
        "6. Store the JSON response\n",
        "7. Convert the JSON into a python dictionary with the entities and salience scores (adjust rounding as needed)\n",
        "8. Convert the keys to lower case (for comparing)\n",
        "9. Return the new dictionary to the main script\n"
      ],
      "metadata": {
        "id": "lDcF9nHjXRfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def processhtml(url):\n",
        "\n",
        "    ua = UserAgent() \n",
        "    headers = { 'User-Agent': ua.chrome } \n",
        "    res = requests.get(url,headers=headers) \n",
        "    html_page = res.text\n",
        "\n",
        "    url_dict = {}\n",
        "\n",
        "    client = language_v1.LanguageServiceClient()\n",
        "\n",
        "    type_ = enums.Document.Type.HTML\n",
        "\n",
        "    language = \"en\"\n",
        "    document = {\"content\": html_page, \"type\": type_, \"language\": language}\n",
        "\n",
        "    encoding_type = enums.EncodingType.UTF8\n",
        "\n",
        "    response = client.analyze_entities(document, encoding_type=encoding_type)\n",
        "\n",
        "    for entity in response.entities:\n",
        "        url_dict[entity.name] = round(entity.salience,4)\n",
        "\n",
        "    url_dict = {k.lower(): v for k, v in url_dict.items()}\n",
        "\n",
        "    return url_dict"
      ],
      "metadata": {
        "id": "m-_uufFcU-jd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Process NLP Data and Calculate Salience Difference\n",
        "Now that we have our function we can set the variables storing the web page URLs we want to compare and then send them to the function we just made."
      ],
      "metadata": {
        "id": "Y_XfFAFeXwsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url1 = \"https://fusionunlimited.co.uk/about-us/\" \n",
        "url2 = \"https://www.twentysixdigital.com/our-services/\" \n",
        "\n",
        "url1_dict = processhtml(url1)\n",
        "url2_dict = processhtml(url2)"
      ],
      "metadata": {
        "id": "inwLyARtU_8y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compare Entities between 2 Webpages \n",
        "df = pd.DataFrame([], columns=['URL 1','URL 2','Difference'])\n",
        "\n",
        "for key in set(url1_dict) & set(url2_dict):\n",
        "    url1_keywordnum = str(url1_dict.get(key,\"n/a\"))\n",
        "    url2_keywordnum = str(url2_dict.get(key,\"n/a\"))\n",
        "    \n",
        "    if url2_keywordnum > url1_keywordnum:\n",
        "        diff = str(round(float(url2_keywordnum) - float(url1_keywordnum),3))\n",
        "    else:\n",
        "        diff = \"0\"\n",
        "\n",
        "    new_row = {'Keyword':key,'URL 1':url1_keywordnum,'URL 2':url2_keywordnum,'Difference':diff}\n",
        "    \n",
        "    df = df.append(new_row, ignore_index=True)\n",
        "\n",
        "print(df.sort_values(by='Difference', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "3CLuMlSlWd4b",
        "outputId": "96630bd9-4382-4c1f-b0ce-927545825792"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     URL 1   URL 2 Difference      Keyword\n",
            "11  0.0054  0.1121      0.107      clients\n",
            "18  0.0053  0.0113      0.006  strategists\n",
            "32  0.0023  0.0052      0.003     strategy\n",
            "12  0.0016  0.0041      0.003        brand\n",
            "31  0.0016  0.0036      0.002     audience\n",
            "20  0.0013  0.0019      0.001        leeds\n",
            "27  0.0037  0.0042        0.0     approach\n",
            "16   0.005  0.0052        0.0  performance\n",
            "2   0.0052  0.0055        0.0      experts\n",
            "8   0.0028   0.002          0          ppc\n",
            "21  0.0017  0.0015          0        touch\n",
            "30  0.0042  0.0025          0         some\n",
            "29  0.0043  0.0041          0         site\n",
            "28  0.0183  0.0144          0      careers\n",
            "3   0.0049  0.0034          0   affiliates\n",
            "26  0.0177  0.0019          0   experience\n",
            "25  0.0245  0.0178          0     services\n",
            "24  0.0013   0.001          0    instagram\n",
            "23  0.0184  0.0144          0         blog\n",
            "22  0.0043  0.0034          0        blend\n",
            "4   0.0246  0.0163          0      contact\n",
            "9   0.0013   0.001          0     facebook\n",
            "19  0.0013   0.001          0      twitter\n",
            "5   0.0032  0.0011          0        level\n",
            "17  0.0063  0.0042          0        teams\n",
            "1   0.0023   0.001          0     linkedin\n",
            "15  0.0043  0.0011          0     industry\n",
            "14  0.0184  0.0144          0         work\n",
            "13  0.0025   0.002          0          seo\n",
            "6   0.0053  0.0029          0       brands\n",
            "7   0.0043  0.0034          0           pr\n",
            "10     0.0     0.0          0            8\n",
            "0      0.0     0.0          0         2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*clients, strategists, strategy, brand, audience, leeds*\n",
        "These are entities found on both pages that are deemed by Google NLP more important (relative to the whole text) on the competitor page. **These are keywords you may want to investigate and consider ways to communicate better on your page.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "üìî URL1 (benchmark) and URL2 (competitor) (contain the **salience scores** for each entity for that URL.\n",
        "If your competitor's salience score for a keyword is greater than yours, record the difference\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "‚ùó **\"Salience score\"** is a metric of calculated importance in relation to the rest of the text."
      ],
      "metadata": {
        "id": "vDYMDW6TZS9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ‚≠êÔ∏è Find Entity Opportunities from Outranking pages ‚≠êÔ∏è\n",
        "diff_lists = set(url2_dict) - set(url1_dict)\n",
        "\n",
        "final_diff = {}\n",
        "\n",
        "for k in diff_lists:\n",
        "  for key,value in url2_dict.items():\n",
        "    if k == key:\n",
        "      final_diff.update({key:value})\n",
        "\n",
        "df = pd.DataFrame(final_diff.items(), columns=['Keyword','Score'])\n",
        "\n",
        "print(df.head(25).sort_values(by='Score', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4kQyK6fbgbT",
        "outputId": "1527f3ad-13bc-4229-9669-6fb4371bfa99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Keyword   Score\n",
            "19                                          twentysix  0.0107\n",
            "4                               performance marketing  0.0093\n",
            "6                                           decisions  0.0063\n",
            "13                                        researchers  0.0061\n",
            "1                                 website development  0.0052\n",
            "11                                   project managers  0.0037\n",
            "15                                           opinions  0.0025\n",
            "5                                              trends  0.0025\n",
            "8                                                 all  0.0025\n",
            "14                                              minds  0.0025\n",
            "20                                        innovations  0.0025\n",
            "3                                    sovereign street  0.0019\n",
            "23                                          marketing  0.0019\n",
            "10                                     privacy policy  0.0018\n",
            "16                                            ls1 4ba  0.0015\n",
            "18                                           partners  0.0014\n",
            "21                                             london  0.0013\n",
            "0                                          bow street  0.0013\n",
            "9                                           advantage  0.0011\n",
            "2                                        social media  0.0011\n",
            "12                                          8th floor  0.0010\n",
            "17  157-159 high street<br/>\\nholywood<br/>\\nbt18 9hu  0.0000\n",
            "22                                                 71  0.0000\n",
            "7                                                2626  0.0000\n",
            "24                                                  7  0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This list shows the **top 25 entities by salience on the competitor page BUT DO NOT appear on your page**.\n",
        "\n",
        "This is useful to find entity opportunities where pages that outrank you are using but you are not.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**‚ö†Ô∏è Entities Opportunities stem from the previous two-folded comparison**"
      ],
      "metadata": {
        "id": "m51hz9PpbzcC"
      }
    }
  ]
}